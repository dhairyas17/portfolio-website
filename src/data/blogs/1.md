When we started, we had around 100 edge devices deployed across construction sites. Within 14 months, we were supporting more than 1,200 active nodes across four continents with real-time video processing, limited connectivity, and strict 24/7 uptime requirements.

We were not scaling a web app. We were scaling mission-critical edge infrastructure. Here is how we did it.

### Ground Reality: What Scaling Edge Really Means

Traditional web product scaling involves APIs, UIs, and cloud infrastructure. Scaling edge systems is far messier.

- Devices in unpredictable physical environments  
- Connectivity that breaks often  
- Hardware that may overheat, fail, or get misconfigured  
- Limited over-the-air update capabilities  
- Compliance and regulatory constraints across regions  

As a TPM, my job was to translate this operational chaos into a clear, executable roadmap for engineering, operations, and product stakeholders.

### Product and Platform Strategy

We split the product into three core tracks:

![Move Right Icon](/assets/table/1-1-table.png)

**Strategic decision:** We moved from manual device provisioning to a self-registration bootstrap protocol, reducing deployment friction by 70%.

### Technical Execution and Alignment

**Challenges**

- Limited device observability  
- Coordinating AI model deployments with version tracking and rollback  
- Hardware fragmentation across Nvidia Jetsons, Raspberry Pis, and custom boards  

**Solutions**

- Built a custom metrics and log forwarder over MQTT, routed to Prometheus and Grafana  
- Integrated model versioning via MLflow, accessible through the device's local agent  
- Established a hardware compatibility matrix and firmware validator  

### Metrics That Mattered

![Move Right Icon](/assets/table/1-table.png)

### Leading Cross-Functional Execution

I worked across:

- Hardware Engineering for specification validation and thermal compliance  
- DevOps for CI/CD pipelines and secrets management  
- AI and ML Engineers for modularizing models for edge inferencing  
- Support and Operations for the feedback loop from field failures  
- Customers for device usage patterns and custom requirements  

Weekly war rooms, monthly OKR reviews, and quarterly roadmap adjustments kept everyone aligned and proactive rather than reactive.

### Key Learnings

- Edge environments are not the same as cloud. A stable AWS service means nothing if your SBC overheats in 45Â°C heat.  
- Observability is your lifeline. Without metrics, you are blind.  
- Rollbacks are essential. No firmware or model rollout is flawless.  
- Operations teams are the closest to the truth. Listen to them.  
- TPMs must understand the system end to end, not just manage project timelines.  

### Impact Summary

- Scaled deployments from about 100 devices to more than 1,200  
- Reduced provisioning time from hours to minutes  
- Improved AI model release velocity with minimal rollback risk  
- Built scalable systems for remote device health, logging, and updates
